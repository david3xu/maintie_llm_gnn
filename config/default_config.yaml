# MaintIE LLM-GNN Configuration Template

project:
  name: "maintie_llm_gnn"
  version: "1.0.0"
  description: "MaintIE LLM-GNN Hybrid Information Extraction"

data:
  # TODO: Configure data paths
  raw_data_path: "data/raw/"
  processed_data_path: "data/processed/"
  gold_corpus_path: "data/raw/gold_release.json"
  silver_corpus_path: "data/raw/silver_release.json"
  ontology_path: "data/raw/scheme.json"
  
  # TODO: Configure data processing
  train_split: 0.8
  val_split: 0.2
  max_sequence_length: 512

model:
  # TODO: Configure LLM embedder
  llm_embedder:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    embedding_dim: 384
    domain_features_dim: 32
    combined_features_dim: 416
  
  # TODO: Configure GNN architecture
  gnn:
    type: "GAT"  # Options: GAT, GCN, GraphSAGE
    hidden_dim: 256
    num_layers: 2
    num_heads: 8  # For GAT
    dropout: 0.2
  
  # TODO: Configure output dimensions
  num_entity_classes: 224  # FG-3 complexity
  num_relation_classes: 6

graph:
  # TODO: Configure graph construction
  similarity_threshold: 0.75
  k_neighbors: 15
  edge_types:
    - "semantic_similarity"
    - "entity_cooccurrence" 
    - "equipment_hierarchy"
    - "procedure_similarity"

training:
  # TODO: Configure training parameters
  batch_size: 32
  num_epochs: 100
  learning_rate: 0.001
  weight_decay: 0.0001
  early_stopping_patience: 10
  
  # TODO: Configure loss weights
  entity_loss_weight: 1.0
  relation_loss_weight: 1.0

evaluation:
  # TODO: Configure evaluation settings
  metrics:
    - "precision"
    - "recall" 
    - "f1_score"
  complexity_levels:
    - "FG-0"
    - "FG-1"
    - "FG-2" 
    - "FG-3"
